<h1>Setup Guide - Docker</h1>

#### To run a worker to process submissions

If you're just attaching to a queue go to the [run a compute worker](#run-a-compute-worker) section.


#### To run an entire instance of the Codalab website

You'll need to create a storage container (AWS S3 or Azure) and configure a `.env` file which will store your settings like: storage keys, SSL certificate paths and ports that are open.

# Complete website setup

## 1. Environment

### - On Mac/Linux

Clone the project and make a copy of `.env_sample` (or `.env_production_sample` if you're creating a production server) called `.env` in the root of the project directory:

1. Install Docker CE (Community Edition) use the [mac installer here](https://download.docker.com/mac/stable/Docker.dmg), which is complete with docker-compose.
    + For Ubuntu, follow [command line installation instructions here](https://docs.docker.com/engine/installation/linux/ubuntu/#install-docker)). Note: If you're using Ubuntu, you'll also need to install manually install [docker-compose](https://docs.docker.com/compose/install/). If you have [Pip](https://pip.pypa.io/en/stable/installing/) installed on your system, you can do this with `pip install docker-compose`
2. `git clone https://github.com/codalab/codalab-competitions.git`
3. `cd codalab-competitions`
4. `cp .env_sample .env`


### - On Windows

*TODO describe how to install on Windows*

### - Editing project variables

Open `.env` in your preferred editor, you'll fill this in with your storage keys, SSL information, etc.

**Be sure to replace passwords/secrets!**


```ini
# Here are some important settings to consider:
# =============================================
# Always set the secret key!
DJANGO_SECRET_KEY=something-random

# For storage you'll want to choose AWS or S3, and comment out or delete the other one
# DEFAULT_FILE_STORAGE=storages.backends.s3boto.S3BotoStorage
# ... and rest of AWS settings
#
# or
# DEFAULT_FILE_STORAGE=codalab.azure_storage.AzureStorage  
# ... and rest of Azure storage settings

# Change the secrets, passwords, and ports if you're going to open up the rest, 
# but with just the default setup and port 80 open the only other thing you may have
# to worry about is SSL. The bottom of this doc has a section on SSL
```

# 2. Storage

Codalab gives you the option of using AWS or Azure as your storage of choice. Depending on vendor you use, **you must comment out the one you are not using in the `.env` file.**

## - AWS S3

Sign in or create an AWS account [here](https://aws.amazon.com/s3/) and then create a private and public bucket.


### Creating buckets

1. You don't have to do this if you've already setup Azure Blob Storage!
1. Sign into the AWS Management Console and open the Amazon S3 console [here](https://console.aws.amazon.com/console/)
1. Type `S3` into the Services Search bar, and navigate to the S3 console
1. Create 2 buckets, one named `"whatever-public"` and another `"whatever-private"`
1. Click **Create Bucket**
1. In the **Create a Bucket** dialog box, in the **Bucket Name** box, enter a bucket name. You'll need two buckets, one public and one private. Let's create the public bucket first. Name it `whatever-public`
1. In the **Region** box, select US West 2.
1. Click **Create**
1. Create another bucket: Click **Create Bucket**
1. In the **Create a Bucket** dialog box, in the **Bucket Name** box, enter a bucket name for your private bucket. Something like `whatever-private`
1. Put these bucket names in your `.env` under `AWS_STORAGE_BUCKET_NAME` and `AWS_STORAGE_PRIVATE_BUCKET_NAME`
1. Make sure the `DEFAULT_FILE_STORAGE` `.env` option is set to `storages.backends.s3boto.S3BotoStorage`

### Setting CORS

Make sure you have your bucket highlighted, click properties button, then click permissions tab. Now edit CORS.

![properties-s3-bucket-perm](https://cloud.githubusercontent.com/assets/13974084/24004263/3808545a-0a3c-11e7-9377-906128e83382.jpg)


In both buckets set CORS as follows:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<CORSConfiguration xmlns="http://s3.amazonaws.com/doc/2006-03-01/">
    <CORSRule>
        <AllowedOrigin>*</AllowedOrigin>
        <AllowedMethod>PUT</AllowedMethod>
        <AllowedMethod>POST</AllowedMethod>
        <AllowedMethod>GET</AllowedMethod>
        <MaxAgeSeconds>3000</MaxAgeSeconds>
        <AllowedHeader>*</AllowedHeader>
    </CORSRule>
</CORSConfiguration>
```

![image](https://cloud.githubusercontent.com/assets/2185159/23929355/b0d1ce94-08e2-11e7-90af-02ee57d0fcf0.png)

![image](https://cloud.githubusercontent.com/assets/2185159/23929367/d406ecaa-08e2-11e7-8ec2-d44a4014ee3b.png)

### Setting Bucket Policies

If you don't already have a user (via Identity and Access Management -- IAM), you'll need to create that [here](https://aws.amazon.com/iam/) and put those key/secret values into your `.env` under `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`.

If you're new to IAM you'll need to complete the following steps:
1. Add User
![add user](https://cloud.githubusercontent.com/assets/13974084/24004744/809aaadc-0a3d-11e7-9c2a-df0a0d9c3813.png)

1. Set user to have programmatic access
![programmatic access](https://cloud.githubusercontent.com/assets/13974084/24004748/866b4a3e-0a3d-11e7-8419-abb9841b5e8a.png)

1. Your permissions don't need to be set. Continue to the next step.
![scary permissions box](https://cloud.githubusercontent.com/assets/13974084/24004793/aa1fbc58-0a3d-11e7-80ca-5f8ba9d9f668.png)

1. Copy your special `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` for this user.
![access key and id](https://cloud.githubusercontent.com/assets/13974084/24004836/c6776f5e-0a3d-11e7-88bc-c49f25345907.png)

1. Copy your username, you'll need it for setting up Policies on your `public` and `private` buckets. ![username](https://cloud.githubusercontent.com/assets/13974084/24005099/749f0524-0a3e-11e7-8724-a7776298321b.png)


**Public**


<img width="446" alt="perms" src="https://cloud.githubusercontent.com/assets/13974084/24005414/58168be2-0a3f-11e7-90ef-61b43b98fa2f.png">

The following policy will allow anyone to download this data, like competition logos:

```json
{
    "Version": "2008-10-17",
    "Statement": [
        {
            "Sid": "PublicReadForGetBucketObjects",
            "Effect": "Allow",
            "Principal": {
                "AWS": "*"
            },
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::your-bucket-local/*"
        },
        {
            "Sid": "",
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::12345:user/name"
            },
            "Action": "s3:*",
            "Resource": [
                "arn:aws:s3:::your-bucket-local",
                "arn:aws:s3:::your-bucket-local/*"
            ]
        }
    ]
}
```


**Private**

The following policy will disallow people from downloading competitions and submission data, but will retain your access (`root`) and a separate IAM policy (`user/name`):

```json
{
    "Version": "2008-10-17",
    "Statement": [
        {
            "Sid": "DenyAllButMe",
            "Effect": "Allow",
            "Principal": {
                "AWS": [
                    "arn:aws:iam::12345:user/name",
                    "arn:aws:iam::12345:root"
                ]
            },
            "Action": "s3:*",
            "Resource": [
                "arn:aws:s3:::your-bucket-private",
                "arn:aws:s3:::your-bucket-private/*"
            ]
        },
        {
            "Sid": "DenyAllButMe",
            "Effect": "Deny",
            "NotPrincipal": {
                "AWS": [
                    "arn:aws:iam::12345:user/name",
                    "arn:aws:iam::12345:root"
                ]
            },
            "Action": "s3:*",
            "Resource": [
                "arn:aws:s3:::your-bucket-private",
                "arn:aws:s3:::your-bucket-private/*"
            ]
        }
    ]
}
```

## - Azure blob storage

You may sign up for an Azure account [here](https://azure.microsoft.com/en-us/), then follow the directions below.

1. You do not have to do this if you've already setup S3!
1. Log on to the [Azure Portal](https://portal.azure.com).
1. From the Dashboard, click **Storage accounts** on the left.
1. Click Add at the top of the page to create a new storage account.
1. If you don't already have a subscription, create one now. The free trial requires a credit card, and **deletes all your storage containers after 90 days**, unless you upgrade to a different plan i.e. 'Pay as You Go'.
1. Select the **Classic** storage account. Refer to the image below for settings.
<img src="https://cloud.githubusercontent.com/assets/13974084/24454290/5371a67a-1459-11e7-9ba7-6db751ed9e50.png" width="350">

1. In the dashboard, click **All Resources/All Subscriptions** and then click on your username. Click **Access Keys** and Copy your account name and access key to `.env` under `AZURE_ACCOUNT_NAME` and `AZURE_ACCOUNT_KEY`.
<img src="https://cloud.githubusercontent.com/assets/13974084/24456145/15fc68b4-1460-11e7-9c27-52d9a1f34146.png" width="450">

1. Within that same user account, click on **Containers** and Add a new container.
<img src="https://cloud.githubusercontent.com/assets/13974084/24454599/7112bee8-145a-11e7-99c8-3d3c13160210.png" width="750">

1. Create a new container named "bundles". Set the **Access** to "Private".
1. Add another container named "public". Set the **Access** to "Public Blob".
<img src="https://cloud.githubusercontent.com/assets/13974084/24456261/7c21d93a-1460-11e7-8c6c-b271d5dd8a5e.png" width="750">
1. Make sure the `DEFAULT_FILE_STORAGE` `.env` option is set to `codalab.azure_storage.AzureStorage`

# 3. Running docker

Make sure your domain is set properly in your `.env`. If you are running locally, `CODALAB_SITE_DOMAIN=localhost` is fine. For our main website we use `CODALAB_SITE_DOMAIN=codalab.org`.

To run the server navigate to the root directory of the git repo, near the `docker-compose.yml` file and start docker:

```
docker-compose up -d
```

[Read here](https://docs.docker.com/engine/admin/host_integration/#using-a-process-manager) to auto-start docker when your OS boots.



# 4. Extras

## - Logging

To change where logs are kept, modify `LOG_DIR` in your `.env` configuration file.

## - SSL

Place your certs in the `certs/` folder and specify them in your `.env`, i.e. if you put a cert named `localhost` into your `certs` folder you'd change `.env` to:

```bash
SSL_CERTIFICATE=/app/certs/localhost.crt
SSL_CERTIFICATE_KEY=/app/certs/localhost.key
```

Change your RabbitMQ ports to the SSL versions which are `5671` and `15671`:
```bash
RABBITMQ_PORT=5671
RABBITMQ_MANAGEMENT_PORT=15671
```

Make sure you have ports `80` and `443` open on the machine.


# Compute worker (only) setup

This is *only* for users running workers for the "Worker Management Queues":

* Install docker ([mac](https://download.docker.com/mac/stable/Docker.dmg) or [Ubuntu](https://docs.docker.com/engine/installation/linux/ubuntu/#install-docker))
* `git clone git@github.com:codalab/codalab-competitions.git`
* `cd codalab-competitions`
* `cp .env_sample .env`

Edit `.env` and set your `BROKER_URL` from the worker management screen: <br> ![image](https://cloud.githubusercontent.com/assets/2185159/23891328/f3b62dd0-0852-11e7-8da4-12e5dd8a7383.png)

Now your configuration file should look something like this:

```
BROKER_URL=pyamqp://cd980e2d-78f9-4707-868d-bdfdd071...
```

Then you can run the worker:

```
$ docker-compose start worker_compute
```
